benchmark: ARC-AGI-1
description: Accuracy on ARC-AGI-1
results:
  Human Panel: 98
  Stem Grad: 98
  Avg. Mturker: 77
  o3-preview (Low)*: 75.7
  o3 (High): 60.8
  o3-Pro (High): 59.3
  o4-mini (High): 58.7
  o3-Pro (Medium): 57
  ARChitects: 56
  o3 (Medium): 53.8
  o3-Pro (Low): 44.3
  o4-mini (Medium): 41.8
  o3 (Low): 41.5
  Gemini 2.5 Pro (Thinking 16K): 41
  Claude Sonnet 4 (Thinking 16K): 40
  Gemini 2.5 Pro (Thinking 32K): 37
  Claude Opus 4 (Thinking 16K): 35.7
  o3-mini (High): 34.5
  Gemini 2.5 Flash (Preview): 33.3
  Gemini 2.5 Flash (Preview) (Thinking 16K): 33.3
  Gemini 2.5 Flash (Preview) (Thinking 24K): 32.3
  o1 (Medium): 30.7
  Claude Opus 4 (Thinking 8K): 30.7
  Gemini 2.5 Pro (Thinking 8K): 29.5
  Claude Sonnet 4 (Thinking 8K): 29
  Claude 3.7 (16K): 28.6
  Claude Sonnet 4 (Thinking 1K): 28
  Codex Mini (Latest): 27.3
  o1 (Low): 27.2
  Claude Opus 4 (Thinking 1K): 27
  Gemini 2.5 Flash (Preview) (Thinking 8K): 25.8
  Claude Sonnet 4: 23.8
  o1-pro (Low): 23.3
  Claude Opus 4: 22.5
  o3-mini (Medium): 22.3
  o4-mini (Low): 21.3
  Deepseek R1 (05/28): 21.2
  Claude 3.7 (8K): 21.2
  o1-preview: 18
  Icecuber: 17
  Grok 3 Mini (Low): 16.5
  Gemini 2.5 Flash (Preview) (Thinking 1K): 16
  Gemini 2.5 Pro (Thinking 1K): 16
  Deepseek R1: 15.8
  o3-mini (Low): 14.5
  o1-mini: 14
  Claude 3.7: 13.6
  Claude 3.7 (1K): 11.6
  GPT-4.5: 10.3
  Magistral Medium (Thinking): 6.1
  Magistral Medium: 5.9
  GPT-4.1: 5.5
  Grok 3: 5.5
  Magistral Small: 5
  GPT-4o: 4.5
  Llama 4 Maverick: 4.4
  GPT-4.1-Mini: 3.5
  Llama 4 Scout: 0.5
  GPT-4.1-Nano: 0
