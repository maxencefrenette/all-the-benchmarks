benchmark: MathArena SMT 2025
description: Accuracy on MathArena SMT 2025 competition
website: https://matharena.ai/
github: https://github.com/eth-sri/matharena
score_weight: 1
cost_weight: 1
model_name_mapping_file: matharena.yaml
private_holdout: false
results:
  Claude-3.7-Sonnet (Think): 56.60377358490564
  DeepSeek-R1: 66.98113207547168
  DeepSeek-R1-0528: 83.01886792452831
  DeepSeek-R1-Distill-14B: 54.71698113207544
  DeepSeek-R1-Distill-32B: 60.377358490566
  DeepSeek-R1-Distill-70B: 60.84905660377355
  Grok 3 Mini (high): 78.77358490566037
  Grok 3 Mini (low): 63.679245283018844
  Grok 4: 85.84905660377358
  Qwen3-235B-A22B: 76.88679245283016
  Qwen3-30B-A3B: 67.92452830188675
  gemini-2.5-flash (think): 75.47169811320752
  gemini-2.5-pro: 84.90566037735847
  o3 (high): 87.73584905660378
  o4-mini (high): 88.67924528301887
  o4-mini (low): 68.86792452830186
  o4-mini (medium): 79.71698113207546
cost_per_task:
  Claude-3.7-Sonnet (Think): 72.66857399999998
  DeepSeek-R1: 4.7859448
  DeepSeek-R1-0528: 9.5299875
  DeepSeek-R1-Distill-14B: 0.39896159999999997
  DeepSeek-R1-Distill-32B: 0.7331976
  DeepSeek-R1-Distill-70B: 1.2843888
  Grok 3 Mini (high): 1.8832605000000004
  Grok 3 Mini (low): 0.6542415999999999
  Grok 4: 39.29826
  Qwen3-235B-A22B: 1.6630739999999997
  Qwen3-30B-A3B: 0.9489782000000003
  gemini-2.5-flash (think): 16.030786199999998
  gemini-2.5-pro: 39.475964999999995
  o3 (high): 75.31123000000002
  o4-mini (high): 9.652192000000001
  o4-mini (low): 1.8971656000000001
  o4-mini (medium): 4.315784
