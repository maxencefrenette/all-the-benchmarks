benchmark: LiveBench
description: Average score across LiveBench categories
website: https://livebench.ai
github: https://github.com/LiveBench/LiveBench
score_weight: 1
cost_weight: 1
results:
  claude-3-7-sonnet-20250219-base: 60.4
  claude-3-7-sonnet-20250219-thinking-64k: 68.64
  claude-4-1-opus-20250805-thinking-32k: 75.25
  claude-4-opus-20250514-base: 67.37
  claude-4-opus-20250514-thinking-32k: 74.81
  claude-4-sonnet-20250514-base: 65.4
  claude-4-sonnet-20250514-thinking-64k: 73.82
  claude-sonnet-4-5-20250929: 70.56
  claude-sonnet-4-5-20250929-thinking-64k: 78.26
  deepseek-v3.1: 63.58
  deepseek-v3.1-terminus: 64.71
  deepseek-v3.1-terminus-thinking: 71.4
  deepseek-v3.1-thinking: 70.77
  gemini-2.5-pro-preview-06-05-default: 72.13
  gemini-2.5-pro-preview-06-05-highthinking: 71.92
  glm-4.5: 65
  gpt-5-2025-08-07: 78.85
  gpt-5-codex: 78.24
  gpt-5-2025-08-07-high: 79.33
  gpt-5-2025-08-07-low: 74.65
  gpt-5-mini-2025-08-07: 71.86
  gpt-5-mini-2025-08-07-high: 75.31
  gpt-5-mini-2025-08-07-low: 65.5
  gpt-5-nano-2025-08-07: 59
  grok-4-0709: 72.84
  grok-4-fast-reasoning: 68.09
  kimi-k2-instruct: 63.77
  o3-2025-04-16-high: 75.81
  o3-2025-04-16-medium: 73.66
  o3-pro-2025-06-10-high: 75.82
  o4-mini-2025-04-16-high: 72.73
  o4-mini-2025-04-16-medium: 67.23
  qwen3-coder-480b-a35b-instruct: 61.66
  qwen3-max-2025-09-23: 69.86
  gpt-5-pro-2025-10-06: 78.73
  gemini-2.5-flash-preview-05-20: 64.68
  grok-code-fast-1-0825: 59.37
  glm-4.6: 71.22
model_name_mapping_file: livebench.yaml
private_holdout: true
