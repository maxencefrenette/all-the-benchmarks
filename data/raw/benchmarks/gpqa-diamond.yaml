benchmark: GPQA Diamond
description: Score on GPQA Diamond benchmark
website: https://artificialanalysis.ai/evaluations/gpqa-diamond
github: null
score_weight: 1
cost_weight: 1
results:
  Grok 4: 87
  GPT-5 (high): 85
  o3-pro: 84
  Gemini 2.5 Pro: 84
  GPT-5 (medium): 84
  Gemini 2.5 Pro (Mar '25): 83
  o3: 82
  Gemini 2.5 Pro (May' 25): 82
  DeepSeek R1 0528: 81
  GPT-5 (low): 80
  GPT-5 mini: 80
  Claude 4 Opus Thinking: 79
  Grok 3 mini Reasoning (high): 79
  Gemini 2.5 Flash (Reasoning): 79
  Qwen3 235B 2507 (Reasoning): 79
  o4-mini (high): 78
  gpt-oss-120B (high): 78
  GLM-4.5: 78
  Claude 4 Sonnet Thinking: 77
  o3-mini (high): 77
  Claude 3.7 Sonnet Thinking: 77
  Kimi K2: 76
  Qwen3 235B 2507 (Non-reasoning): 75
  o3-mini: 74
  Llama Nemotron Super 49B v1.5 (Reasoning): 74
  o1: 74
  EXAONE 4.0 32B (Reasoning): 73
  GLM-4.5-Air: 73
  Llama Nemotron Ultra Reasoning: 72
  DeepSeek R1 (Jan '25): 70
  Qwen3 30B 2507 (Reasoning): 70
  Claude 4 Opus: 70
  Gemini 2.0 Flash Thinking exp. (Jan '25): 70
  Qwen3 235B (Reasoning): 70
  Gemini 2.5 Flash (April '25) (Reasoning): 69
  MiniMax M1 80k: 69
  Grok 3: 69
  Solar Pro 2 (Reasoning): 68
  Gemini 2.5 Flash: 68
  Claude 4 Sonnet: 68
  MiniMax M1 40k: 68
  Magistral Medium: 67
  GPT-5 (minimal): 67
  Llama 4 Maverick: 67
  GPT-5 nano: 67
  Qwen3 32B (Reasoning): 66
  GPT-4.1: 66
  GPT-4.1 mini: 66
  Qwen3 30B 2507 (Non-reasoning): 65
  Claude 3.7 Sonnet: 65
  GPT-4o (March 2025): 65
  DeepSeek V3 0324 (Mar '25): 65
  Llama 3.3 Nemotron Super 49B Reasoning: 64
  Magistral Small: 64
  Gemini 2.0 Flash (exp): 63
  EXAONE 4.0 32B: 62
  Gemini 2.5 Flash-Lite (Reasoning): 62
  Gemini 2.0 Flash: 62
  Sonar Reasoning: 62
  Gemini 2.0 Pro Experimental: 62
  Qwen3 Coder 480B: 61
  gpt-oss-20B (high): 61
  Qwen3 30B (Reasoning): 61
  DeepSeek R1 Distill Qwen 32B: 61
  Qwen3 235B: 61
  DeepSeek R1 0528 Qwen3 8B: 61
  Qwen3 14B (Reasoning): 60
  o1-mini: 60
  Claude 3.5 Sonnet (Oct): 59
  Gemini 2.5 Flash (April '25): 59
  QwQ-32B: 59
  Gemini 1.5 Pro (Sep): 58
  Qwen3 8B (Reasoning): 58
  Mistral Medium 3.1: 58
  Llama 4 Scout: 58
  Qwen2.5 Max: 58
  Mistral Medium 3: 57
  MiniMax-Text-01: 57
  Sonar Pro: 57
  Solar Pro 2  (Reasoning): 57
  Phi-4: 57
  NVIDIA Nemotron Nano 9B V2 (Reasoning): 57
  Nova Premier: 56
  Solar Pro 2: 54
  Claude 3.5 Sonnet (June): 56
  DeepSeek V3 (Dec '24): 55
  QwQ 32B-Preview: 55
  GPT-4o (Nov '24): 54
  Gemini 2.0 Flash-Lite (Preview): 54
  Gemini 2.0 Flash-Lite (Feb '25): 53
  Qwen3 32B: 53
  Reka Flash 3: 52
  Command A: 52
  GPT-4o (May '24): 52
  Qwen3 4B (Reasoning): 52
  GPT-4o (Aug '24): 52
  Llama 3.3 Nemotron Super 49B v1: 51
  Qwen3 Coder 30B: 51
  Tulu3 405B: 51
  Llama 3.1 405B: 51
  Qwen3 30B: 51
  GPT-4.1 nano: 51
  GPT-4o (ChatGPT): 51
  Grok 2: 51
  Mistral Small 3.2: 50
  Pixtral Large: 50
  Nova Pro: 49
  Llama 3.3 70B: 49
  Devstral Medium: 49
  Qwen2.5 72B: 49
  Claude 3 Opus: 48
  Mistral Large 2 (Nov '24): 48
  DeepSeek R1 Distill Qwen 14B: 48
  Llama Nemotron Super 49B v1.5: 48
  Gemini 2.5 Flash-Lite: 47
  Mistral Large 2 (Jul '24): 47
  Sonar: 47
  Grok Beta: 47
  Qwen3 14B: 47
  Qwen2.5 Instruct 32B: 46
  Llama 3.1 Nemotron 70B: 46
  Gemini 1.5 Flash (Sep): 46
  Mistral Small 3: 46
  Mistral Small 3.1: 45
  Qwen3 8B: 45
  Devstral Small (May '25): 43
  Nova Lite: 43
  Llama 3.2 90B (Vision): 43
  Gemma 3 27B: 42
  Jamba 1.5 Large: 42
  GPT-4o mini: 42
  Mistral Saba: 42
  Qwen2.5 Coder 32B: 41
  Devstral Small: 41
  Qwen2.5 Turbo: 41
  Llama 3.1 70B: 40
  Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning): 40
  Claude 3.5 Haiku: 40
  DeepSeek R1 Distill Llama 70B: 40
  Hermes 3 - Llama-3.1 70B: 40
  Claude 3 Sonnet: 40
  Qwen3 4B: 39
  Jamba 1.7 Large: 39
  Jamba 1.6 Large: 38
  DeepHermes 3 - Mistral 24B: 38
  Mistral Small (Sep '24): 38
  Llama 3 70B: 37
  Gemini 1.5 Pro (May): 37
  Qwen2 72B: 37
  Yi-Large: 36
  Gemini 1.5 Flash-8B: 35
  Nova Micro: 35
  Gemma 2 27B: 35
  Qwen3 1.7B (Reasoning): 35
  Mistral Large (Feb '24): 35
  Gemma 3 12B: 34
  Mistral Medium: 34
  Claude 2.0: 34
  Pixtral 12B: 34
  Qwen2.5 Coder 7B: 33
  Granite 3.3 8B: 33
  Command-R+: 33
  Mixtral 8x22B: 33
  Phi-4 Mini: 33
  DBRX: 33
  Claude Instant: 33
  Llama 2 Chat 70B: 32
  LFM 40B: 32
  Phi-3 Medium 14B: 32
  Gemini 1.5 Flash (May): 32
  Command-R+ (Apr '24): 32
  Jamba 1.7 Mini: 32
  Llama 2 Chat 13B: 32
  Claude 2.1: 31
  DeepSeek Coder V2 Lite: 31
  Phi-3 Mini: 31
  Phi-4 Multimodal: 31
  Mistral NeMo: 31
  Codestral (Jan '25): 31
  Gemma 2 9B: 31
  Mistral Small (Feb '24): 30
  DeepSeek R1 Distill Llama 8B: 30
  Jamba 1.5 Mini: 30
  Jamba 1.6 Mini: 30
  GPT-3.5 Turbo: 29
  Gemma 3n E4B: 29
  Llama 3 8B: 29
  Mixtral 8x7B: 29
  Gemma 3 4B: 29
  Command-R: 28
  Qwen1.5 Chat 110B: 28
  Command-R (Mar '24): 28
  Qwen3 1.7B: 28
  Gemma 3n E4B (May '25): 27
  Gemini 1.0 Pro: 27
  Ministral 8B: 27
  Jamba Instruct: 27
  DeepHermes 3 - Llama-3.1 8B: 27
  Ministral 3B: 26
  Llama 3.1 8B: 25
  Llama 3.2 3B: 25
  Codestral (May '24): 25
  Aya Expanse 8B: 24
  Qwen3 0.6B (Reasoning): 23
  Gemma 3 1B: 23
  Qwen3 0.6B: 23
  Aya Expanse 32B: 23
  OpenChat 3.5: 23
  Gemma 3n E2B: 22
  Llama 2 Chat 7B: 22
  Llama 3.2 11B (Vision): 22
  Codestral-Mamba: 21
  Llama 3.2 1B: 19
  Mistral 7B: 17
  DeepSeek R1 Distill Qwen 1.5B: 9
model_name_mapping_file: artificial-analysis.yaml
private_holdout: false
cost_per_task:
  o3-pro: 56
  o1: 45
  Claude 4 Opus Thinking: 32
  Grok 4: 27
  Claude 3.7 Sonnet Thinking: 27
  Gemini 2.5 Pro (May' 25): 25
  Gemini 2.5 Pro: 16
  GPT-5 (high): 14
  Qwen3 235B 2507 (Reasoning): 14
  Claude 4 Sonnet Thinking: 12
  Magistral Medium: 11
  Qwen3 235B (Reasoning): 11
  o3: 10
  Gemini 2.5 Pro (Mar '25): 10
  Gemini 2.5 Flash (April '25) (Reasoning): 8
  Qwen3 32B (Reasoning): 8
  Claude 4 Opus: 8
  GPT-5 (medium): 7
  o4-mini (high): 7
  o3-mini (high): 6
  Claude 3 Opus: 5
  MiniMax M1 40k: 5
  Gemini 2.5 Flash (Reasoning): 4
  DeepSeek R1 (Jan '25): 4
  Qwen3 14B (Reasoning): 4
  Sonar Reasoning: 4
  DeepSeek R1 0528: 4
  GLM-4.5: 4
  Qwen3 30B 2507 (Reasoning): 3
  Magistral Small: 3
  GPT-5 (low): 3
  Grok 3: 3
  Qwen3 8B (Reasoning): 3
  o3-mini: 3
  Qwen3 30B (Reasoning): 2
  Qwen3 1.7B (Reasoning): 2
  GPT-4o (March 2025): 2
  GLM-4.5-Air: 2
  Llama Nemotron Ultra Reasoning: 2
  EXAONE 4.0 32B (Reasoning): 2
  Claude 4 Sonnet: 2
  Qwen3 0.6B (Reasoning): 2
  o1-mini: 2
  Reka Flash 3: 2
  QwQ-32B: 2
  GPT-4o (May '24): 2
  Qwen3 235B 2507 (Non-reasoning): 1
  Claude 3.7 Sonnet: 1
  Qwen3 4B (Reasoning): 1
  GPT-4o (ChatGPT): 1
  gpt-oss-120B (high): 1
  Command A: 1
  GPT-4o (Aug '24): 1
  Claude 3.5 Sonnet (June): 1
  GPT-4o (Nov '24): 1
  Command-R+ (Apr '24): 1
  Gemini 2.5 Flash-Lite (Reasoning): 1
  Kimi K2: 1
  Claude 2.1: 1
  Qwen3 Coder 480B: 1
  Sonar Pro: 1
  GPT-4.1: 1
  Claude 3.5 Sonnet (Oct): 1
  GPT-5 mini: 1
  Qwen2.5 Max: 1
  Claude 3 Sonnet: 1
  Nova Premier: 1
  Jamba 1.5 Large: 1
  Mistral Large (Feb '24): 1
  Gemini 2.5 Flash: 1
  DeepSeek R1 Distill Qwen 14B: 1
  Grok 3 mini Reasoning (high): 1
  Command-R+: 1
  DeepSeek R1 Distill Llama 70B: 1
  Mistral Medium: 1
  Jamba 1.7 Large: 1
  Pixtral Large: 1
  GPT-5 (minimal): 1
  Jamba 1.6 Large: 1
  Llama 3.1 405B: 1
  Mistral Large 2 (Nov '24): 1
  Mixtral 8x22B: 1
  Solar Pro 2 (Reasoning): 1
  Mistral Large 2 (Jul '24): 1
  Qwen3 32B: 0
  Gemini 2.5 Flash-Lite: 0
  Qwen3 30B 2507 (Non-reasoning): 0
  Qwen3 235B: 0
  GPT-5 nano: 0
  QwQ 32B-Preview: 0
  Qwen3 Coder 30B: 0
  Mistral Medium 3.1: 0
  gpt-oss-20B (high): 0
  DeepSeek R1 Distill Qwen 32B: 0
  Nova Pro: 0
  EXAONE 4.0 32B: 0
  GPT-4.1 mini: 0
  Mistral Medium 3: 0
  Gemini 2.5 Flash (April '25): 0
  Claude 3.5 Haiku: 0
  Sonar: 0
  DeepSeek V3 0324 (Mar '25): 0
  Devstral Medium: 0
  Llama 4 Maverick: 0
  DeepSeek R1 0528 Qwen3 8B: 0
  Llama 3.2 90B (Vision): 0
  Qwen3 8B: 0
  Qwen3 14B: 0
  DeepSeek V3 (Dec '24): 0
  Llama 3.1 70B: 0
  Qwen3 30B: 0
  Mistral Small (Feb '24): 0
  Aya Expanse 32B: 0
  Llama 3.3 70B: 0
  Gemini 1.0 Pro: 0
  Aya Expanse 8B: 0
  MiniMax-Text-01: 0
  Codestral (Jan '25): 0
  Claude Instant: 0
  Llama 4 Scout: 0
  Mixtral 8x7B: 0
  Gemma 2 27B: 0
  Qwen3 0.6B: 0
  Llama 3 70B: 0
  GPT-4o mini: 0
  Command-R (Mar '24): 0
  GPT-3.5 Turbo: 0
  Phi-4: 0
  Qwen3 4B: 0
  Mistral Saba: 0
  Llama 3.2 11B (Vision): 0
  GPT-4.1 nano: 0
  Phi-3 Medium 14B: 0
  MiniMax M1 80k: 0
  Gemini 2.0 Flash: 0
  Llama 3.1 Nemotron 70B: 0
  Jamba 1.5 Mini: 0
  Mistral Small (Sep '24): 0
  Gemini 2.0 Flash-Lite (Preview): 0
  Codestral (May '24): 0
  Jamba 1.6 Mini: 0
  Mistral Small 3.2: 0
  Gemini 2.0 Flash-Lite (Feb '25): 0
  Qwen2.5 Instruct 32B: 0
  Qwen3 1.7B: 0
  Devstral Small: 0
  Devstral Small (May '25): 0
  Mistral Small 3.1: 0
  Granite 3.3 8B: 0
  Mistral 7B: 0
  Mistral Small 3: 0
  Qwen2.5 Coder 32B: 0
  DeepSeek R1 Distill Llama 8B: 0
  Jamba 1.7 Mini: 0
  Command-R: 0
  Nova Lite: 0
  Phi-3 Mini: 0
  Qwen2.5 Turbo: 0
  Llama 3.1 8B: 0
  Pixtral 12B: 0
  Gemma 2 9B: 0
  Gemma 3 12B: 0
  Llama 2 Chat 7B: 0
  Hermes 3 - Llama-3.1 70B: 0
  Llama 3.2 1B: 0
  Mistral NeMo: 0
  Ministral 8B: 0
  Llama 3.2 3B: 0
  LFM 40B: 0
  Nova Micro: 0
  Gemma 3n E4B: 0
  Llama 3 8B: 0
  Gemma 3 4B: 0
  Ministral 3B: 0
