benchmark: GPQA Diamond
description: Score on GPQA Diamond benchmark
website: https://artificialanalysis.ai/evaluations/gpqa-diamond
github: null
score_weight: 1
cost_weight: 1
results:
  Grok 4: 87
  GPT-5 (high): 85
  o3-pro: 84
  Gemini 2.5 Pro: 84
  GPT-5 (medium): 84
  Gemini 2.5 Pro (Mar): 83
  GPT-5 mini (high): 82
  o3: 82
  Gemini 2.5 Pro (May): 82
  DeepSeek R1 0528: 81
  Claude 4.1 Opus: 80
  GPT-5 (low): 80
  GPT-5 mini (medium): 80
  Claude 4 Opus: 70
  Grok 3 mini Reasoning (high): 79
  Gemini 2.5 Flash: 59
  Qwen3 235B 2507: 75
  o4-mini (high): 78
  gpt-oss-120B (high): 78
  GLM-4.5: 78
  DeepSeek V3.1: 73
  Claude 4 Sonnet: 68
  o3-mini (high): 77
  Claude 3.7 Sonnet: 65
  Kimi K2 0905: 76
  Kimi K2: 76
  Qwen3 Max (Preview): 76
  Qwen3 Next 80B A3B: 73
  o3-mini: 74
  Llama Nemotron Super 49B v1.5: 48
  o1: 74
  EXAONE 4.0 32B: 62
  GLM-4.5-Air: 73
  Llama Nemotron Ultra: 72
  Grok Code Fast 1: 72
  Hermes 4 405B: 53
  DeepSeek R1 (Jan): 70
  Qwen3 30B 2507: 65
  Gemini 2.0 Flash Thinking exp. (Jan): 70
  Qwen3 235B: 61
  Hermes 4 - Llama-3.1 70B: 69
  MiniMax M1 80k: 69
  Grok 3: 69
  GPT-5 mini (minimal): 68
  Solar Pro 2: 54
  GLM-4.5V: 57
  MiniMax M1 40k: 68
  Magistral Medium: 67
  GPT-5 nano (high): 67
  GPT-5 (minimal): 67
  Llama 4 Maverick: 67
  GPT-5 nano (medium): 67
  Qwen3 32B: 53
  Qwen3 4B 2507: 66
  GPT-4.1: 66
  GPT-4.1 mini: 66
  GPT-4o (Mar): 65
  DeepSeek V3 0324: 65
  Llama 3.3 Nemotron Super 49B: 64
  Magistral Small: 64
  Gemini 2.0 Flash (exp): 63
  Gemini 2.5 Flash-Lite: 47
  Gemini 2.0 Flash: 62
  Sonar Reasoning: 62
  Gemini 2.0 Pro Experimental: 62
  Qwen3 Coder 480B: 61
  gpt-oss-20B (high): 61
  Qwen3 30B: 51
  DeepSeek R1 Distill Qwen 32B: 61
  DeepSeek R1 0528 Qwen3 8B: 61
  Qwen3 14B: 47
  o1-mini: 60
  Claude 3.5 Sonnet (Oct): 59
  QwQ-32B: 59
  Gemini 1.5 Pro (Sep): 58
  Qwen3 8B: 45
  Mistral Medium 3.1: 58
  Llama 4 Scout: 58
  Qwen2.5 Max: 58
  Mistral Medium 3: 57
  MiniMax-Text-01: 57
  Sonar Pro: 57
  Phi-4: 57
  NVIDIA Nemotron Nano 9B V2: 55
  Nova Premier: 56
  Claude 3.5 Sonnet (June): 56
  DeepSeek V3 (Dec): 55
  QwQ 32B-Preview: 55
  GPT-4o (Nov): 54
  Gemini 2.0 Flash-Lite (Preview): 54
  Gemini 2.0 Flash-Lite (Feb): 53
  Reka Flash 3: 52
  Command A: 52
  GPT-4o (May): 52
  Qwen3 4B: 39
  GPT-4o (Aug): 52
  Llama 3.3 Nemotron Super 49B v1: 51
  Qwen3 Coder 30B: 51
  Tulu3 405B: 51
  Llama 3.1 405B: 51
  Exaone 4.0 1.2B: 42
  GPT-4.1 nano: 51
  GPT-4o (ChatGPT): 51
  Grok 2: 51
  Mistral Small 3.2: 50
  Pixtral Large: 50
  Nova Pro: 49
  Llama 3.3 70B: 49
  Devstral Medium: 49
  Hermes 4 70B: 49
  Qwen2.5 72B: 49
  Claude 3 Opus: 48
  Mistral Large 2 (Nov): 48
  DeepSeek R1 Distill Qwen 14B: 48
  Mistral Large 2 (Jul): 47
  Sonar: 47
  Grok Beta: 47
  Qwen2.5 Instruct 32B: 46
  Llama 3.1 Nemotron 70B: 46
  Gemini 1.5 Flash (Sep): 46
  Mistral Small 3: 46
  Mistral Small 3.1: 45
  Devstral Small (May): 43
  Nova Lite: 43
  Llama 3.2 90B (Vision): 43
  GPT-5 nano (minimal): 42
  Gemma 3 27B: 42
  Jamba 1.5 Large: 42
  GPT-4o mini: 42
  Mistral Saba: 42
  Qwen2.5 Coder 32B: 41
  Devstral Small: 41
  Qwen2.5 Turbo: 41
  Llama 3.1 70B: 40
  Llama 3.1 Nemotron Nano 4B v1.1: 40
  Claude 3.5 Haiku: 40
  DeepSeek R1 Distill Llama 70B: 40
  Hermes 3 - Llama-3.1 70B: 40
  Claude 3 Sonnet: 40
  Jamba 1.7 Large: 39
  Jamba 1.6 Large: 38
  DeepHermes 3 - Mistral 24B: 38
  Mistral Small (Sep): 38
  Llama 3 70B: 37
  Gemini 1.5 Pro (May): 37
  Qwen2 72B: 37
  Yi-Large: 36
  Gemini 1.5 Flash-8B: 35
  Nova Micro: 35
  Gemma 2 27B: 35
  Qwen3 1.7B: 28
  Mistral Large (Feb): 35
  Gemma 3 12B: 34
  Mistral Medium: 34
  Claude 2.0: 34
  Pixtral 12B: 34
  Qwen2.5 Coder 7B: 33
  Granite 3.3 8B: 33
  Command-R+: 33
  Mixtral 8x22B: 33
  Phi-4 Mini: 33
  DBRX: 33
  Claude Instant: 33
  Llama 2 Chat 70B: 32
  LFM 40B: 32
  Phi-3 Medium 14B: 32
  Gemini 1.5 Flash (May): 32
  Command-R+ (Apr): 32
  Jamba 1.7 Mini: 32
  Llama 2 Chat 13B: 32
  Claude 2.1: 31
  DeepSeek Coder V2 Lite: 31
  Phi-3 Mini: 31
  Phi-4 Multimodal: 31
  Mistral NeMo: 31
  Codestral (Jan): 31
  Gemma 2 9B: 31
  Mistral Small (Feb): 30
  DeepSeek R1 Distill Llama 8B: 30
  Jamba 1.5 Mini: 30
  Jamba 1.6 Mini: 30
  GPT-3.5 Turbo: 29
  Gemma 3n E4B: 29
  Llama 3 8B: 29
  Mixtral 8x7B: 29
  Gemma 3 4B: 29
  Command-R: 28
  Qwen1.5 Chat 110B: 28
  Command-R (Mar): 28
  Gemma 3n E4B (May): 27
  Gemini 1.0 Pro: 27
  Ministral 8B: 27
  Jamba Instruct: 27
  DeepHermes 3 - Llama-3.1 8B: 27
  Ministral 3B: 26
  Llama 3.1 8B: 25
  Llama 3.2 3B: 25
  Codestral (May): 25
  Aya Expanse 8B: 24
  Qwen3 0.6B: 23
  Gemma 3 1B: 23
  Aya Expanse 32B: 23
  OpenChat 3.5: 23
  Gemma 3n E2B: 22
  LFM2 1.2B: 22
  Llama 2 Chat 7B: 22
  Llama 3.2 11B (Vision): 22
  Codestral-Mamba: 21
  Llama 3.2 1B: 19
  Mistral 7B: 17
  DeepSeek R1 Distill Qwen 1.5B: 9
model_name_mapping_file: artificial-analysis.yaml
private_holdout: false
cost_per_task:
  o3-pro: 56
  o1: 45
  Claude 4.1 Opus: 35
  Claude 4 Opus: 8
  Grok 4: 27
  Claude 3.7 Sonnet: 1
  Gemini 2.5 Pro (May): 25
  Gemini 2.5 Pro: 16
  GPT-5 (high): 14
  Qwen3 235B 2507: 1
  Qwen3 Next 80B A3B: 1
  Claude 4 Sonnet: 2
  Magistral Medium: 11
  Qwen3 235B: 0
  o3: 10
  Gemini 2.5 Pro (Mar): 10
  Qwen3 32B: 0
  GPT-5 (medium): 7
  o4-mini (high): 7
  o3-mini (high): 6
  Claude 3 Opus: 5
  MiniMax M1 40k: 5
  DeepSeek R1 (Jan): 4
  Qwen3 14B: 0
  Sonar Reasoning: 4
  GLM-4.5: 4
  DeepSeek R1 0528: 4
  Qwen3 30B 2507: 0
  Magistral Small: 3
  Grok Code Fast 1: 3
  GPT-5 (low): 3
  GPT-5 mini (high): 3
  Grok 3: 3
  Qwen3 8B: 0
  o3-mini: 3
  Qwen3 30B: 0
  Qwen3 1.7B: 0
  DeepSeek V3.1: 0
  GPT-4o (Mar): 2
  QwQ-32B: 2
  GLM-4.5-Air: 2
  Llama Nemotron Ultra: 2
  EXAONE 4.0 32B: 0
  Qwen3 0.6B: 0
  o1-mini: 2
  Reka Flash 3: 2
  GPT-4o (May): 2
  Qwen3 Max (Preview): 2
  Qwen3 4B: 0
  Kimi K2 0905: 1
  GPT-4o (ChatGPT): 1
  gpt-oss-120B (high): 1
  Command A: 1
  GPT-4o (Aug): 1
  GLM-4.5V: 0
  Claude 3.5 Sonnet (June): 1
  GPT-4o (Nov): 1
  Command-R+ (Apr): 1
  Gemini 2.5 Flash-Lite: 0
  Kimi K2: 1
  Claude 2.1: 1
  Qwen3 Coder 480B: 1
  Sonar Pro: 1
  GPT-4.1: 1
  Claude 3.5 Sonnet (Oct): 1
  GPT-5 mini (medium): 1
  GPT-5 nano (high): 1
  Qwen2.5 Max: 1
  Claude 3 Sonnet: 1
  Nova Premier: 1
  Jamba 1.5 Large: 1
  Mistral Large (Feb): 1
  DeepSeek R1 Distill Qwen 14B: 1
  Grok 3 mini Reasoning (high): 1
  Command-R+: 1
  Mistral Medium: 1
  Llama 3.1 405B: 1
  DeepSeek R1 Distill Llama 70B: 1
  Jamba 1.7 Large: 1
  Hermes 4 - Llama-3.1 70B: 1
  Pixtral Large: 1
  GPT-5 (minimal): 1
  Jamba 1.6 Large: 1
  Mistral Large 2 (Nov): 1
  Mixtral 8x22B: 1
  Mistral Large 2 (Jul): 1
  GPT-5 nano (medium): 0
  QwQ 32B-Preview: 0
  Qwen3 Coder 30B: 0
  Hermes 4 405B: 0
  Mistral Medium 3.1: 0
  gpt-oss-20B (high): 0
  DeepSeek R1 Distill Qwen 32B: 0
  Nova Pro: 0
  GPT-4.1 mini: 0
  Mistral Medium 3: 0
  Claude 3.5 Haiku: 0
  Sonar: 0
  DeepSeek V3 0324: 0
  Devstral Medium: 0
  Llama 4 Maverick: 0
  DeepSeek R1 0528 Qwen3 8B: 0
  Llama 3.2 90B (Vision): 0
  DeepSeek V3 (Dec): 0
  GPT-5 mini (minimal): 0
  Llama 3.1 70B: 0
  Mistral Small (Feb): 0
  Llama 3.3 70B: 0
  Aya Expanse 32B: 0
  Gemini 1.0 Pro: 0
  Aya Expanse 8B: 0
  Llama 4 Scout: 0
  MiniMax-Text-01: 0
  Codestral (Jan): 0
  Claude Instant: 0
  Mixtral 8x7B: 0
  Llama 3 70B: 0
  Gemma 3 12B: 0
  GPT-4o mini: 0
  Command-R (Mar): 0
  GPT-3.5 Turbo: 0
  Phi-4: 0
  Mistral Saba: 0
  Llama 3.2 11B (Vision): 0
  GPT-4.1 nano: 0
  Phi-3 Medium 14B: 0
  MiniMax M1 80k: 0
  Gemini 2.0 Flash: 0
  Llama 3.1 Nemotron 70B: 0
  Jamba 1.5 Mini: 0
  Mistral Small (Sep): 0
  Gemini 2.0 Flash-Lite (Preview): 0
  Codestral (May): 0
  Jamba 1.6 Mini: 0
  Mistral Small 3.2: 0
  Gemini 2.0 Flash-Lite (Feb): 0
  Qwen2.5 Instruct 32B: 0
  Qwen2.5 Coder 32B: 0
  Hermes 4 70B: 0
  Devstral Small: 0
  Devstral Small (May): 0
  Mistral Small 3.1: 0
  Granite 3.3 8B: 0
  Mistral 7B: 0
  Mistral Small 3: 0
  DeepSeek R1 Distill Llama 8B: 0
  Jamba 1.7 Mini: 0
  Command-R: 0
  Nova Lite: 0
  Phi-3 Mini: 0
  Llama 3.1 8B: 0
  Qwen2.5 Turbo: 0
  Pixtral 12B: 0
  Gemma 2 9B: 0
  Llama 2 Chat 7B: 0
  Hermes 3 - Llama-3.1 70B: 0
  Gemma 3 4B: 0
  Llama 3.2 3B: 0
  Llama 3.2 1B: 0
  Mistral NeMo: 0
  Ministral 8B: 0
  Nova Micro: 0
  Gemma 3n E4B: 0
  Llama 3 8B: 0
  GPT-5 nano (minimal): 0
  Ministral 3B: 0
