benchmark: Artificial Analysis Index
description: Score on Artificial Analysis Index benchmark
score_weight: 1
cost_weight: 1
results:
  Grok 4: 73
  o3-pro: 71
  Gemini 2.5 Pro: 70
  o3: 70
  o4-mini (high): 70
  Gemini 2.5 Pro (Mar '25): 69
  DeepSeek R1 0528 (May '25): 68
  Gemini 2.5 Pro (May' 25): 68
  Grok 3 mini Reasoning (high): 67
  o3-mini (high): 66
  Gemini 2.5 Flash (Reasoning): 65
  Claude 4 Opus Thinking: 64
  MiniMax M1 80k: 63
  o3-mini: 63
  Qwen3 235B (Reasoning): 62
  o1: 62
  MiniMax M1 40k: 61
  Llama Nemotron Ultra Reasoning: 61
  Claude 4 Sonnet Thinking: 61
  Gemini 2.5 Flash (April '25) (Reasoning): 60
  DeepSeek R1 (Jan '25): 60
  o1-preview: 60
  Qwen3 32B (Reasoning): 59
  QwQ-32B: 58
  Claude 4 Opus: 58
  Claude 3.7 Sonnet Thinking: 57
  o1-pro: 56
  Grok 3 Reasoning Beta: 56
  Magistral Medium: 56
  Qwen3 14B (Reasoning): 56
  Qwen3 30B A3B (Reasoning): 56
  Gemini 2.5 Flash-Lite (Reasoning): 55
  Magistral Small: 55
  o1-mini: 54
  Gemini 2.5 Flash: 53
  DeepSeek V3 0324 (Mar '25): 53
  Claude 4 Sonnet: 53
  GPT-4.5 (Preview): 53
  GPT-4.1 mini: 53
  GPT-4.1: 53
  Gemini 2.0 Flash Thinking exp. (Jan '25): 52
  DeepSeek R1 0528 Qwen3 8B: 52
  DeepSeek R1 Distill Qwen 32B: 52
  Qwen3 8B (Reasoning): 51
  Llama 3.3 Nemotron Super 49B Reasoning: 51
  Solar Pro 2  (Reasoning): 51
  Grok 3: 51
  Llama 4 Maverick: 51
  GPT-4o (March 2025): 50
  Gemini 2.0 Pro Experimental: 49
  DeepSeek R1 Distill Qwen 14B: 49
  Mistral Medium 3: 49
  Sonar Reasoning: 49
  Gemini 2.5 Flash (April '25): 49
  DeepSeek R1 Distill Llama 70B: 48
  Claude 3.7 Sonnet: 48
  Gemini 2.0 Flash: 48
  Qwen3 4B (Reasoning): 47
  Reka Flash 3: 47
  Qwen3 235B: 47
  Gemini 2.0 Flash (exp): 46
  Gemini 2.5 Flash-Lite: 46
  DeepSeek V3 (Dec '24): 46
  Qwen2.5 Max: 45
  Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning): 45
  Solar Pro 2: 45
  Gemini 1.5 Pro (Sep): 45
  Claude 3.5 Sonnet (Oct): 44
  Qwen3 32B: 44
  Sonar: 43
  Llama 4 Scout: 43
  Sonar Pro: 43
  QwQ 32B-Preview: 43
  Nova Premier: 43
  Qwen3 30B A3B: 43
  Mistral Small 3.2: 42
  GPT-4o (Nov '24): 41
  Gemini 2.0 Flash-Lite (Feb '25): 41
  Llama 3.3 70B: 41
  GPT-4.1 nano: 41
  Qwen3 14B: 41
  GPT-4o (May '24): 41
  Gemini 2.0 Flash-Lite (Preview): 41
  GPT-4o (Aug '24): 41
  Llama 3.1 405B: 40
  Qwen2.5 72B: 40
  MiniMax-Text-01: 40
  Phi-4: 40
  Claude 3.5 Sonnet (June): 40
  Command A: 40
  Tulu3 405B: 40
  GPT-4o (ChatGPT): 40
  Llama 3.3 Nemotron Super 49B v1: 39
  Grok 2: 39
  Gemini 1.5 Flash (Sep): 39
  GPT-4 Turbo: 39
  Mistral Large 2 (Nov '24): 38
  Qwen3 1.7B (Reasoning): 38
  Gemma 3 27B: 38
  Grok Beta: 38
  Pixtral Large: 37
  Qwen2.5 Instruct 32B: 37
  Llama 3.1 Nemotron 70B: 37
  Nova Pro: 37
  Qwen3 8B: 37
  Mistral Large 2 (Jul '24): 37
  Qwen2.5 Coder 32B: 36
  GPT-4: 36
  GPT-4o mini: 36
  Llama 3.1 70B: 35
  Mistral Small 3.1: 35
  Mistral Small 3: 35
  DeepSeek-V2.5 (Dec '24): 35
  Qwen3 4B: 35
  Claude 3 Opus: 35
  Claude 3.5 Haiku: 35
  Gemini 2.0 Flash Thinking exp. (Dec '24): 35
  DeepSeek-V2.5: 35
  Devstral: 34
  Mistral Saba: 34
  DeepSeek R1 Distill Llama 8B: 34
  Reka Core: 34
  Gemma 3 12B: 34
  Gemini 1.5 Pro (May): 34
  R1 1776: 34
  Qwen2.5 Turbo: 34
  Reka Flash: 34
  Llama 3.2 90B (Vision): 33
  Solar Mini: 33
  Reka Flash (Feb '24): 33
  Reka Edge: 33
  Grok-1: 33
  Qwen2 72B: 33
  Nova Lite: 33
  Gemma 2 27B: 32
  Gemini 1.5 Flash-8B: 31
  DeepHermes 3 - Mistral 24B: 30
  Jamba 1.5 Large: 29
  Hermes 3 - Llama-3.1 70B: 29
  DeepSeek-Coder-V2: 29
  Jamba 1.6 Large: 29
  Gemini 1.5 Flash (May): 28
  Nova Micro: 28
  Gemma 3n E4B: 28
  Yi-Large: 28
  Claude 3 Sonnet: 28
  Codestral (Jan '25): 28
  Llama 3 70B: 27
  Mistral Small (Sep '24): 27
  Gemini 1.0 Ultra: 27
  Gemma 3n E4B (May '25): 27
  Phi-4 Multimodal: 27
  Qwen2.5 Coder 7B: 27
  Mistral Large (Feb '24): 26
  Jamba Instruct: 26
  Mixtral 8x22B: 26
  Phi-4 Mini: 26
  Gemma 3 4B: 25
  Llama 3.2 11B (Vision): 25
  Qwen3 1.7B: 25
  Qwen1.5 Chat 110B: 25
  Phi-3 Medium 14B: 25
  Claude 2.1: 24
  Claude 3 Haiku: 24
  Llama 3.1 8B: 24
  Pixtral 12B: 23
  Qwen3 0.6B (Reasoning): 23
  Claude 2.0: 23
  DeepSeek-V2: 23
  Mistral Small (Feb '24): 23
  Mistral Medium: 23
  GPT-3.5 Turbo: 23
  Ministral 8B: 22
  Gemma 2 9B: 22
  Phi-3 Mini: 22
  Arctic: 22
  Qwen Chat 72B: 22
  LFM 40B: 22
  Command-R+: 21
  Llama 3 8B: 21
  PALM-2: 21
  Gemini 1.0 Pro: 21
  DeepSeek Coder V2 Lite: 20
  Codestral (May '24): 20
  Aya Expanse 32B: 20
  Llama 2 Chat 70B: 20
  DeepSeek LLM 67B (V1): 20
  Llama 2 Chat 13B: 20
  Command-R+ (Apr '24): 20
  OpenChat 3.5: 20
  DBRX: 20
  Ministral 3B: 20
  Mistral NeMo: 20
  Llama 3.2 3B: 20
  DeepSeek R1 Distill Qwen 1.5B: 19
  Jamba 1.5 Mini: 18
  Jamba 1.6 Mini: 18
  Mixtral 8x7B: 17
  Qwen3 0.6B: 17
  DeepHermes 3 - Llama-3.1 8B: 16
  Aya Expanse 8B: 16
  Command-R: 15
  Command-R (Mar '24): 15
  Qwen Chat 14B: 14
  Claude Instant: 14
  Codestral-Mamba: 14
  Gemma 3 1B: 13
  Llama 65B: 11
  Mistral 7B: 10
  Llama 3.2 1B: 10
  Llama 2 Chat 7B: 8
model_name_mapping_file: artificial-analysis.yaml
cost_per_task:
  o1: 2767
  Claude 4 Opus Thinking: 2036
  Grok 4: 1630
  Claude 3.7 Sonnet Thinking: 1485
  Gemini 2.5 Pro (May' 25): 1335
  Gemini 2.5 Pro: 971
  Gemini 2.5 Pro (Mar '25): 859
  Magistral Medium: 744
  Qwen3 235B (Reasoning): 627
  Claude 4 Opus: 551
  Qwen3 32B (Reasoning): 459
  Gemini 2.5 Flash (April '25) (Reasoning): 445
  Claude 3 Opus: 411
  o3: 390
  o3-mini (high): 345
  Claude 4 Sonnet Thinking: 342
  o4-mini (high): 323
  Gemini 2.5 Flash (Reasoning): 319
  DeepSeek R1 (Jan '25): 291
  MiniMax M1 40k: 261
  Qwen3 14B (Reasoning): 221
  DeepSeek R1 0528 (May '25): 220
  Magistral Small: 208
  Qwen3 0.6B (Reasoning): 158
  Grok 3: 154
  Qwen3 8B (Reasoning): 150
  o3-mini: 143
  Qwen3 30B A3B (Reasoning): 143
  o1-mini: 141
  GPT-4o (March 2025): 128
  Claude 4 Sonnet: 119
  Qwen3 1.7B (Reasoning): 109
  Claude 3.7 Sonnet: 109
  GPT-4o (May '24): 109
  Llama Nemotron Ultra Reasoning: 106
  Grok Beta: 103
  Claude 2.1: 100
  Reka Flash 3: 100
  Claude 3.5 Sonnet (Oct): 81
  Command A: 80
  Sonar Pro: 80
  Qwen3 4B (Reasoning): 77
  Nova Premier: 76
  Claude 3 Sonnet: 74
  Command-R+ (Apr '24): 68
  GPT-4o (Aug '24): 68
  GPT-4o (Nov '24): 66
  GPT-4.1: 65
  Qwen2.5 Max: 62
  Mistral Large (Feb '24): 61
  Gemini 2.5 Flash-Lite (Reasoning): 55
  QwQ-32B: 54
  Command-R+: 52
  Jamba 1.5 Large: 52
  Grok 3 mini Reasoning (high): 49
  Mistral Medium: 47
  Pixtral Large: 42
  Jamba 1.6 Large: 42
  Mixtral 8x22B: 41
  Mistral Large 2 (Nov '24): 38
  Llama 3.1 405B: 38
  Mistral Large 2 (Jul '24): 36
  Gemini 1.5 Pro (Sep): 29
  Gemini 1.5 Pro (May): 26
  Qwen3 32B: 26
  Qwen3 235B: 23
  Claude 3.5 Haiku: 20
  Gemini 2.5 Flash-Lite: 19
  Nova Pro: 18
  Mistral Medium 3: 17
  GPT-4.1 mini: 16
  DeepSeek R1 Distill Qwen 32B: 14
  DeepSeek V3 0324 (Mar '25): 13
  Sonar: 13
  Mistral Small (Feb '24): 12
  Gemini 2.5 Flash (April '25): 12
  DeepSeek R1 Distill Qwen 14B: 11
  Gemini 2.5 Flash: 11
  Llama 4 Maverick: 10
  Qwen3 14B: 10
  Llama 3.1 70B: 10
  Qwen3 8B: 9
  Gemini 1.0 Pro: 9
  DeepSeek R1 0528 Qwen3 8B: 9
  DeepSeek V3 (Dec '24): 9
  MiniMax-Text-01: 9
  Aya Expanse 32B: 9
  Llama 3.3 70B: 8
  Aya Expanse 8B: 8
  Qwen3 30B A3B: 7
  Mixtral 8x7B: 7
  Gemma 2 27B: 6
  Llama 3.2 90B (Vision): 6
  Llama 4 Scout: 6
  Command-R (Mar '24): 6
  Codestral (Jan '25): 6
  Llama 3 70B: 6
  Qwen3 4B: 5
  Phi-4: 4
  GPT-4o mini: 4
  Phi-3 Medium 14B: 4
  Gemini 2.0 Flash: 3
  Llama 3.1 Nemotron 70B: 3
  Mistral Small (Sep '24): 3
  Qwen3 1.7B: 3
  Codestral (May '24): 3
  GPT-4.1 nano: 3
  Jamba 1.5 Mini: 3
  Jamba 1.6 Mini: 3
  Mistral 7B: 3
  Mistral Small 3.2: 3
  Gemini 2.0 Flash-Lite (Preview): 3
  Qwen2.5 Instruct 32B: 2
  Gemini 2.0 Flash-Lite (Feb '25): 2
  Mistral Small 3: 2
  Mistral Small 3.1: 2
  Command-R: 2
  Qwen2.5 Coder 32B: 2
  Devstral: 2
  DeepSeek R1 Distill Llama 8B: 2
  Gemini 1.5 Flash (Sep): 2
  Llama 3.1 8B: 2
  Gemma 2 9B: 2
  Qwen2.5 Turbo: 2
  Pixtral 12B: 2
  Gemini 1.5 Flash (May): 1
  Nova Lite: 1
  Qwen3 0.6B: 1
  Llama 2 Chat 7B: 1
  Mistral NeMo: 1
  Gemma 3 12B: 1
  LFM 40B: 1
  Ministral 8B: 1
  Gemini 1.5 Flash-8B: 1
  Nova Micro: 1
  Llama 3.2 1B: 1
  Llama 3 8B: 1
  Llama 3.2 3B: 1
  Gemma 3 4B: 0
  Ministral 3B: 0
